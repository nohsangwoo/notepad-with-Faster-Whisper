"use client";

import { WEBSOCKET_URL } from "@/app/shared/api/transcription";
import { concatenateAudioBuffers, createWavFromAudioBuffer } from "@/app/shared/lib/audio/audioUtils";
import { VoiceActivityDetectionConfig } from "@/app/shared/types/audio";
import { useState, useRef, useCallback, useEffect } from "react";

export function useRealTimeRecognition() {
  const [isRealTimeRecording, setIsRealTimeRecording] = useState<boolean>(false);
  const [transcription, setTranscription] = useState<string>("");
  
  // ì›¹ì†Œì¼“ ë° ì˜¤ë””ì˜¤ ê´€ë ¨ ì°¸ì¡°
  const websocketRef = useRef<WebSocket | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const audioDataRef = useRef<Uint8Array | null>(null);
  const processorRef = useRef<ScriptProcessorNode | null>(null);
  const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  
  // VAD ì„¤ì •
  const silenceDetectionRef = useRef<VoiceActivityDetectionConfig>({
    triggered: false,
    silentFrames: 0,
    voicedFrames: 0,
    audioBuffer: [],
    silenceThreshold: 0.01,
    minSilentFrames: 15,
    silentFrameThreshold: 0.015,
  });
  
  // ì‹œë¦¬ ìŠ¤íƒ€ì¼ ìŒì„± ê°ì§€ ë° ì²˜ë¦¬
  const processSiriStyleAudio = useCallback((audioProcessingEvent: AudioProcessingEvent) => {
    const inputBuffer = audioProcessingEvent.inputBuffer;
    const inputData = inputBuffer.getChannelData(0);
    
    // ìŒì„± í™œì„±í™” ê°ì§€ (VAD)
    let sum = 0;
    
    // ì…ë ¥ ë°ì´í„°ì˜ ë³¼ë¥¨ ê³„ì‚° (RMS)
    for (let i = 0; i < inputData.length; i++) {
      const absValue = Math.abs(inputData[i]);
      sum += absValue * absValue;
    }
    
    const rms = Math.sqrt(sum / inputData.length);
    const isSilent = rms < silenceDetectionRef.current.silentFrameThreshold;
    
    // ìŒì„± ë²„í¼ì— í˜„ì¬ í”„ë ˆì„ ì¶”ê°€
    silenceDetectionRef.current.audioBuffer.push(new Float32Array(inputData));
    
    // ìŒì„± ìƒíƒœ ì—…ë°ì´íŠ¸
    if (!silenceDetectionRef.current.triggered) {
      if (!isSilent) {
        // ìŒì„± ê°ì§€ ì‹œì‘
        console.log("ğŸ™ï¸ ìŒì„± ê°ì§€ë¨ - ë…¹ìŒ ì‹œì‘");
        silenceDetectionRef.current.triggered = true;
        silenceDetectionRef.current.voicedFrames = 1;
        silenceDetectionRef.current.silentFrames = 0;
      }
    } else {
      if (!isSilent) {
        // ìŒì„± ê³„ì† ê°ì§€
        silenceDetectionRef.current.voicedFrames++;
        silenceDetectionRef.current.silentFrames = 0;
      } else {
        // ì¹¨ë¬µ ê°ì§€
        silenceDetectionRef.current.silentFrames++;
        
        // ì¼ì • ì‹œê°„ ì´ìƒ ì¹¨ë¬µì´ ì§€ì†ë˜ë©´ ìŒì„± ì„¸ê·¸ë¨¼íŠ¸ ì¢…ë£Œ
        if (silenceDetectionRef.current.silentFrames > silenceDetectionRef.current.minSilentFrames) {
          console.log(`âœ… ìŒì„± ì„¸ê·¸ë¨¼íŠ¸ ì¢…ë£Œ (ìŒì„± í”„ë ˆì„: ${silenceDetectionRef.current.voicedFrames})`);
          
          if (silenceDetectionRef.current.voicedFrames > 5) { // ìµœì†Œí•œì˜ ìœ ì˜ë¯¸í•œ ìŒì„± í”„ë ˆì„ ìˆ˜
            // ì˜¤ë””ì˜¤ ë°ì´í„° ì¤€ë¹„ ë° ì „ì†¡
            const allAudioData = concatenateAudioBuffers(silenceDetectionRef.current.audioBuffer);
            
            // WAV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            const wavBuffer = createWavFromAudioBuffer(allAudioData, 16000);
            
            // ì›¹ì†Œì¼“ìœ¼ë¡œ ì „ì†¡
            if (websocketRef.current?.readyState === WebSocket.OPEN) {
              websocketRef.current.send(wavBuffer);
            }
          }
          
          // ìƒíƒœ ì´ˆê¸°í™”
          silenceDetectionRef.current.triggered = false;
          silenceDetectionRef.current.voicedFrames = 0;
          silenceDetectionRef.current.silentFrames = 0;
          silenceDetectionRef.current.audioBuffer = [];
        }
      }
    }
    
    // ë²„í¼ê°€ ë„ˆë¬´ ì»¤ì§€ì§€ ì•Šë„ë¡ ì œí•œ
    if (silenceDetectionRef.current.audioBuffer.length > 300) { // ì•½ 10ì´ˆ ë¶„ëŸ‰
      silenceDetectionRef.current.audioBuffer = [];
      silenceDetectionRef.current.triggered = false;
      silenceDetectionRef.current.voicedFrames = 0;
      silenceDetectionRef.current.silentFrames = 0;
      console.log("âš ï¸ ì˜¤ë””ì˜¤ ë²„í¼ê°€ ë„ˆë¬´ ì»¤ì„œ ì´ˆê¸°í™”ë¨");
    }
  }, []);
  
  // ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì‹œì‘
  const startRealTimeRecording = useCallback(async () => {
    try {
      // ì´ë¯¸ ì‹¤ì‹œê°„ ë…¹ìŒì´ ì§„í–‰ ì¤‘ì´ë¼ë©´ ì¤‘ì§€ í›„ ì¬ì‹œì‘
      if (isRealTimeRecording) {
        await stopRealTimeRecording();
        // ë¦¬ì†ŒìŠ¤ ì •ë¦¬ë¥¼ ìœ„í•´ ì•½ê°„ì˜ ì§€ì—° ì¶”ê°€
        await new Promise(resolve => setTimeout(resolve, 300));
      }
      
      // WebSocket ì—°ê²°
      websocketRef.current = new WebSocket(WEBSOCKET_URL);
      
      // ì›¹ì†Œì¼“ ì—°ê²° íƒ€ì„ì•„ì›ƒ ì„¤ì •
      const wsConnectionTimeout = setTimeout(() => {
        if (websocketRef.current?.readyState !== WebSocket.OPEN) {
          console.error("WebSocket ì—°ê²° íƒ€ì„ì•„ì›ƒ");
          setTranscription("ì„œë²„ ì—°ê²° ì˜¤ë¥˜: ì›¹ì†Œì¼“ ì—°ê²° ì‹œê°„ ì´ˆê³¼. ë°±ì—”ë“œ ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.");
          if (websocketRef.current) {
            websocketRef.current.close();
            websocketRef.current = null;
          }
          setIsRealTimeRecording(false);
        }
      }, 5000); // 5ì´ˆ íƒ€ì„ì•„ì›ƒ
      
      websocketRef.current.onopen = () => {
        console.log("WebSocket ì—°ê²°ë¨");
        clearTimeout(wsConnectionTimeout);
        setIsRealTimeRecording(true);
      };
      
      websocketRef.current.onmessage = (event) => {
        const text = event.data;
        console.log("ì„œë²„ë¡œë¶€í„° ì‘ë‹µ ë°›ìŒ:", text);
        if (text && text.trim() !== "") {
          setTranscription(text);
        }
      };
      
      websocketRef.current.onerror = (error) => {
        console.error("WebSocket ì˜¤ë¥˜:", error);
        setTranscription("ì›¹ì†Œì¼“ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë°±ì—”ë“œ ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.");
      };
      
      websocketRef.current.onclose = (event) => {
        console.log(`WebSocket ì—°ê²° ì¢…ë£Œ (ì½”ë“œ: ${event.code}, ì´ìœ : ${event.reason})`);
        clearTimeout(wsConnectionTimeout);
        setIsRealTimeRecording(false);
      };
      
      // ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì„¤ì •
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        } 
      });
      
      streamRef.current = stream;
      
      // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
      try {
        const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)({
          sampleRate: 16000,
          latencyHint: 'interactive'
        });
        
        audioContextRef.current = audioContext;
        
        // ì˜¤ë””ì˜¤ ì†ŒìŠ¤ ë° ë¶„ì„ê¸° ìƒì„±
        const source = audioContext.createMediaStreamSource(stream);
        sourceRef.current = source;
        
        // ì˜¤ë””ì˜¤ ì²˜ë¦¬ ë…¸ë“œ ìƒì„±
        const processor = audioContext.createScriptProcessor(4096, 1, 1);
        processorRef.current = processor;
        
        // VAD ë¶„ì„ì„ ìœ„í•œ ë¶„ì„ê¸° ë…¸ë“œ ìƒì„±
        const analyser = audioContext.createAnalyser();
        analyser.fftSize = 2048;
        analyserRef.current = analyser;
        
        const audioData = new Uint8Array(analyser.frequencyBinCount);
        audioDataRef.current = audioData;
        
        // ì—°ê²°: ì†ŒìŠ¤ -> ë¶„ì„ê¸° -> í”„ë¡œì„¸ì„œ -> ì¶œë ¥
        source.connect(analyser);
        source.connect(processor);
        processor.connect(audioContext.destination);
        
        // ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì„¤ì •
        processor.onaudioprocess = processSiriStyleAudio;
        
        // ì´ˆê¸°í™”
        silenceDetectionRef.current = {
          triggered: false,
          silentFrames: 0,
          voicedFrames: 0,
          audioBuffer: [],
          silenceThreshold: 0.01,
          minSilentFrames: 15,
          // ì¹¨ë¬µ ì„ê³„ê°’ ì¡°ì • - ë” ë‚®ì€ ê°’ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ìŒì„± ê°ì§€ ë¯¼ê°ë„ í–¥ìƒ
          silentFrameThreshold: 0.015, 
        };
        
        setIsRealTimeRecording(true);
      } catch (audioError) {
        console.error("ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì„¤ì • ì˜¤ë¥˜:", audioError);
        // ì˜¤ë¥˜ ë°œìƒ ì‹œ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
        if (stream) {
          stream.getTracks().forEach(track => track.stop());
        }
        if (websocketRef.current) {
          websocketRef.current.close();
          websocketRef.current = null;
        }
        throw audioError;
      }
    } catch (error) {
      console.error("ì‹¤ì‹œê°„ ë…¹ìŒ ì‹œì‘ ì˜¤ë¥˜:", error);
      setTranscription("ì„œë²„ ì—°ê²° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë°±ì—”ë“œ ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.");
      setIsRealTimeRecording(false);
    }
  }, [isRealTimeRecording, processSiriStyleAudio]);

  // ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì¢…ë£Œ
  const stopRealTimeRecording = useCallback(() => {
    return new Promise<void>((resolve) => {
      if (isRealTimeRecording) {
        console.log("ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì •ë¦¬ ì¤‘...");
        
        // ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ì§€
        if (processorRef.current) {
          try {
            processorRef.current.disconnect();
          } catch (e) {
            console.warn("í”„ë¡œì„¸ì„œ ì—°ê²° í•´ì œ ì˜¤ë¥˜:", e);
          }
          processorRef.current = null;
        }
        
        if (sourceRef.current) {
          try {
            sourceRef.current.disconnect();
          } catch (e) {
            console.warn("ì†ŒìŠ¤ ì—°ê²° í•´ì œ ì˜¤ë¥˜:", e);
          }
          sourceRef.current = null;
        }
        
        if (audioContextRef.current) {
          try {
            audioContextRef.current.close();
          } catch (e) {
            console.warn("ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì¢…ë£Œ ì˜¤ë¥˜:", e);
          }
          audioContextRef.current = null;
        }
        
        // ë¶„ì„ê¸° ì •ë¦¬
        analyserRef.current = null;
        audioDataRef.current = null;
        
        // ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ
        if (streamRef.current) {
          streamRef.current.getTracks().forEach(track => {
            try {
              track.stop();
            } catch (e) {
              console.warn("íŠ¸ë™ ì¢…ë£Œ ì˜¤ë¥˜:", e);
            }
          });
          streamRef.current = null;
        }
        
        // WebSocket ì—°ê²° ì¢…ë£Œ
        if (websocketRef.current) {
          try {
            // WebSocketì´ ì•„ì§ ì—°ê²° ì¤‘ì´ë¼ë©´ ì •ìƒ ì¢…ë£Œ
            if (websocketRef.current.readyState === WebSocket.OPEN || 
                websocketRef.current.readyState === WebSocket.CONNECTING) {
              websocketRef.current.close(1000, "ì‚¬ìš©ìê°€ ë…¹ìŒ ì¢…ë£Œ");
            }
          } catch (e) {
            console.warn("ì›¹ì†Œì¼“ ì¢…ë£Œ ì˜¤ë¥˜:", e);
          }
          websocketRef.current = null;
        }
        
        // VAD ìƒíƒœ ì´ˆê¸°í™”
        silenceDetectionRef.current = {
          triggered: false,
          silentFrames: 0,
          voicedFrames: 0,
          audioBuffer: [],
          silenceThreshold: 0.01,
          minSilentFrames: 15,
          silentFrameThreshold: 0.3,
        };
        
        setIsRealTimeRecording(false);
        
        // ì•½ê°„ì˜ ì§€ì—° í›„ì— ì •ë¦¬ ì™„ë£Œ ì•Œë¦¼
        setTimeout(() => {
          console.log("ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ");
          resolve();
        }, 100);
      } else {
        resolve();
      }
    });
  }, [isRealTimeRecording]);

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
  useEffect(() => {
    return () => {
      console.log("ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ - ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘");
      
      // ì‹¤ì‹œê°„ ë…¹ìŒ ì •ë¦¬
      if (processorRef.current) {
        try {
          processorRef.current.disconnect();
        } catch (e) {
          console.warn("í”„ë¡œì„¸ì„œ ì—°ê²° í•´ì œ ì˜¤ë¥˜:", e);
        }
        processorRef.current = null;
      }
      
      if (sourceRef.current) {
        try {
          sourceRef.current.disconnect();
        } catch (e) {
          console.warn("ì†ŒìŠ¤ ì—°ê²° í•´ì œ ì˜¤ë¥˜:", e);
        }
        sourceRef.current = null;
      }
      
      if (audioContextRef.current) {
        try {
          audioContextRef.current.close();
        } catch (e) {
          console.warn("ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì¢…ë£Œ ì˜¤ë¥˜:", e);
        }
        audioContextRef.current = null;
      }
      
      if (streamRef.current) {
        try {
          streamRef.current.getTracks().forEach(track => track.stop());
        } catch (e) {
          console.warn("ìŠ¤íŠ¸ë¦¼ íŠ¸ë™ ì •ë¦¬ ì˜¤ë¥˜:", e);
        }
        streamRef.current = null;
      }
      
      // WebSocket ì—°ê²° ì¢…ë£Œ
      if (websocketRef.current) {
        try {
          websocketRef.current.close();
        } catch (e) {
          console.warn("ì›¹ì†Œì¼“ ì¢…ë£Œ ì˜¤ë¥˜:", e);
        }
        websocketRef.current = null;
      }
    };
  }, []);

  return {
    isRealTimeRecording,
    transcription,
    startRealTimeRecording,
    stopRealTimeRecording
  };
} 