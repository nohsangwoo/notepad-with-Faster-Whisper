import asyncio
import websockets
import sounddevice as sd
import numpy as np
import io
import wave
import webrtcvad  # pip install webrtcvad
import time
import collections
import queue
import threading


# ì‹¤í–‰ ë°©ë²•
# python test_siri_like.py --duration 120 (120ì´ˆ ë™ì•ˆ ì‹¤í–‰)

# ì„¤ì •
SAMPLE_RATE = 16000
CHANNELS = 1
FRAME_DURATION_MS = 30  # WebRTC VADëŠ” 10, 20, 30ms í”„ë ˆì„ë§Œ ì§€ì›
VAD_MODE = 3  # 0~3 ë²”ìœ„, 3ì´ ê°€ì¥ ê³µê²©ì (ì¹¨ë¬µ ê°ì§€ì— ë¯¼ê°)
PADDING_DURATION_MS = 300  # ìŒì„± ì „í›„ì— ì¶”ê°€í•  íŒ¨ë”©(ì¹¨ë¬µ) ì‹œê°„
SILENT_CHUNKS_THRESHOLD = 20  # ì´ ê°œìˆ˜ì˜ ì—°ì†ëœ ì¹¨ë¬µ í”„ë ˆì„ì´ ê°ì§€ë˜ë©´ ì¢…ë£Œ

class Audio(object):
    """ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì„ ì²˜ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self, loop, async_queue):
        self.buffer_queue = queue.Queue()
        self.recording = True
        self.vad = webrtcvad.Vad(VAD_MODE)
        self.num_voiced_frames = 0
        self.num_silent_frames = 0
        self.frames = []
        self.loop = loop
        self.async_queue = async_queue

    def frame_generator(self):
        """ì˜¤ë””ì˜¤ í”„ë ˆì„ ìƒì„±ê¸°"""
        while self.recording:
            try:
                data = self.buffer_queue.get(block=True, timeout=1)
                yield data
            except queue.Empty:
                break

    def callback_audio(self, indata, frames, time, status):
        """ì˜¤ë””ì˜¤ ì½œë°± í•¨ìˆ˜"""
        if status:
            print(f"ì˜¤ë””ì˜¤ ìƒíƒœ: {status}")
        self.buffer_queue.put(bytes(indata))

    def vad_collector(self, threshold=SILENT_CHUNKS_THRESHOLD):
        """VADë¥¼ í†µí•´ ìŒì„± êµ¬ê°„ ê²€ì¶œ"""
        frame_duration_ms = FRAME_DURATION_MS
        frame_size = int(SAMPLE_RATE * frame_duration_ms / 1000)
        ring_buffer = collections.deque(maxlen=threshold)
        
        triggered = False
        for frame in self.frame_generator():
            is_speech = self.vad.is_speech(frame, SAMPLE_RATE)
            
            if not triggered:
                if is_speech:
                    triggered = True
                    print("ğŸ™ï¸ ìŒì„± ê°ì§€ë¨ - ë…¹ìŒ ì‹œì‘")
                    for f in ring_buffer:
                        self.frames.append(f)
                    self.frames.append(frame)
                    self.num_voiced_frames += 1
                    ring_buffer.clear()
                else:
                    ring_buffer.append(frame)
            else:
                if is_speech:
                    self.frames.append(frame)
                    self.num_voiced_frames += 1
                    self.num_silent_frames = 0
                else:
                    self.frames.append(frame)
                    self.num_silent_frames += 1
                    
                    # ì¹¨ë¬µì´ ì¼ì • ê¸°ê°„ ê³„ì†ë˜ë©´ ìŒì„± ì„¸ê·¸ë¨¼íŠ¸ ì¢…ë£Œ
                    if self.num_silent_frames > threshold:
                        triggered = False
                        print(f"âœ… ìŒì„± ì„¸ê·¸ë¨¼íŠ¸ ì¢…ë£Œ (ìŒì„± í”„ë ˆì„: {self.num_voiced_frames})")
                        
                        if self.num_voiced_frames > 0:
                            # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë©”ì¸ ìŠ¤ë ˆë“œë¡œ ì•ˆì „í•˜ê²Œ ì „ë‹¬
                            audio_data = b''.join(self.frames)
                            if len(audio_data) > 1000:  # ë„ˆë¬´ ì§§ì€ ì˜¤ë””ì˜¤ëŠ” ë¬´ì‹œ
                                audio_buffer = io.BytesIO()
                                with wave.open(audio_buffer, 'wb') as wav_file:
                                    wav_file.setnchannels(CHANNELS)
                                    wav_file.setsampwidth(2)
                                    wav_file.setframerate(SAMPLE_RATE)
                                    wav_file.writeframes(audio_data)
                                
                                # ë©”ì¸ ì´ë²¤íŠ¸ ë£¨í”„ì˜ íì— ì•ˆì „í•˜ê²Œ ë°ì´í„° ì¶”ê°€
                                self.loop.call_soon_threadsafe(
                                    self.async_queue.put_nowait, 
                                    audio_buffer.getvalue()
                                )
                        
                        self.frames = []
                        self.num_voiced_frames = 0
                        self.num_silent_frames = 0
                        ring_buffer.clear()

async def siri_like_transcribe(duration=60):
    """Siriì²˜ëŸ¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŒì„± ì¸ì‹í•˜ëŠ” í•¨ìˆ˜"""
    print(f"ğŸ¤ Siri ìŠ¤íƒ€ì¼ ìŒì„± ì¸ì‹ ì‹œì‘ (ìµœëŒ€ {duration}ì´ˆ)")
    
    loop = asyncio.get_running_loop()
    audio_queue = asyncio.Queue()
    
    # WebSocket ì—°ê²°
    async with websockets.connect("ws://127.0.0.1:8000/ws/transcribe/") as websocket:
        print("ğŸ”— WebSocket ì„œë²„ ì—°ê²°ë¨")
        
        # ì˜¤ë””ì˜¤ ì²˜ë¦¬ ê°ì²´ ìƒì„± (í˜„ì¬ ì´ë²¤íŠ¸ ë£¨í”„ì™€ í ì „ë‹¬)
        audio = Audio(loop, audio_queue)
        
        # ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì‹œì‘
        frame_duration_ms = FRAME_DURATION_MS
        frame_size = int(SAMPLE_RATE * frame_duration_ms / 1000)
        stream = sd.InputStream(
            samplerate=SAMPLE_RATE,
            channels=CHANNELS,
            dtype=np.int16,
            blocksize=frame_size,
            callback=audio.callback_audio
        )
        
        # VAD ìŠ¤ë ˆë“œ ì‹œì‘
        vad_thread = threading.Thread(target=audio.vad_collector)
        
        try:
            with stream:
                print("ğŸ§ ë“£ê³  ìˆìŠµë‹ˆë‹¤... (ë§ì”€í•˜ì„¸ìš”)")
                vad_thread.start()
                
                # ì‹œê°„ ì œí•œ
                start_time = time.time()
                
                # ìŒì„± ì²˜ë¦¬ ë£¨í”„
                while time.time() - start_time < duration:
                    # ìŒì„± ë°ì´í„° ëŒ€ê¸°
                    try:
                        audio_data = await asyncio.wait_for(audio_queue.get(), timeout=0.5)
                        
                        # WebSocketìœ¼ë¡œ ì „ì†¡
                        await websocket.send(audio_data)
                        
                        # ê²°ê³¼ ìˆ˜ì‹ 
                        response = await websocket.recv()
                        print(f"ğŸ“ ì¸ì‹ ê²°ê³¼: {response}")
                        
                    except asyncio.TimeoutError:
                        # íƒ€ì„ì•„ì›ƒì€ ë¬´ì‹œ
                        pass
                
                print(f"â±ï¸ ìµœëŒ€ ì‹œê°„ ({duration}ì´ˆ)ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
                
        finally:
            # ì •ë¦¬
            audio.recording = False
            if vad_thread.is_alive():
                vad_thread.join(timeout=1)

if __name__ == "__main__":
    asyncio.run(siri_like_transcribe(duration=60)) 